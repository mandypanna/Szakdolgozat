{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BQREHW0YUzV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install git+https://github.com/openai/CLIP.git torch torchvision --upgrade\n",
        "\n",
        "import os, io, math\n",
        "import numpy as np\n",
        "import torch, clip\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODEL_NAME = \"ViT-L/14@336px\"\n",
        "model, preprocess = clip.load(MODEL_NAME, device=device)\n",
        "LOGIT_SCALE = model.logit_scale.exp().detach().cpu().item()\n",
        "\n",
        "TEMP = 1.12\n",
        "DECISION_MODE = \"max\"\n",
        "UNCERT_THRESH = 0.56\n",
        "MARGIN_MIN = 0.05\n",
        "BIAS_DELTA = 0.035\n",
        "W_BUCKET = 0.65\n",
        "W_DIR    = 0.35\n",
        "TOPK_SHOW = 3\n",
        "\n",
        "TEMPLATES_INFANT = [\n",
        "    \"close-up of a baby's hand, {}\",\n",
        "    \"a photo of a baby's hand, {}\",\n",
        "]\n",
        "\n",
        "FIST_PHRASES = [\n",
        "    \"fist\",\n",
        "    \"fingers curled\",\n",
        "    \"thumb tucked\",\n",
        "]\n",
        "\n",
        "OPEN_PHRASES = [\n",
        "    \"open\",\n",
        "    \"fingers extended\",\n",
        "    \"palm visible\",\n",
        "]\n",
        "\n",
        "def build_prompts(phrases, templates):\n",
        "    out = []\n",
        "    for ph in phrases:\n",
        "        for t in templates:\n",
        "            out.append(t.format(ph))\n",
        "\n",
        "    seen=set(); uniq=[]\n",
        "    for s in out:\n",
        "        k=s.lower().strip()\n",
        "        if k not in seen:\n",
        "            uniq.append(s); seen.add(k)\n",
        "    return uniq\n",
        "\n",
        "PROMPTS_FIST = build_prompts(FIST_PHRASES, TEMPLATES_INFANT)\n",
        "PROMPTS_OPEN = build_prompts(OPEN_PHRASES, TEMPLATES_INFANT)\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_texts(texts):\n",
        "    toks = clip.tokenize(texts, truncate=True).to(device)\n",
        "    feats = model.encode_text(toks)\n",
        "    feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "    return feats\n",
        "\n",
        "text_fist = encode_texts(PROMPTS_FIST)\n",
        "text_open = encode_texts(PROMPTS_OPEN)\n",
        "\n",
        "text_fist_mean = text_fist.mean(dim=0); text_fist_mean /= text_fist_mean.norm()\n",
        "text_open_mean = text_open.mean(dim=0); text_open_mean /= text_open_mean.norm()\n",
        "\n",
        "@torch.no_grad()\n",
        "def text_mean(texts):\n",
        "    toks = clip.tokenize(texts, truncate=True).to(device)\n",
        "    feats = model.encode_text(toks)\n",
        "    feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "    return feats.mean(dim=0)\n",
        "\n",
        "NEUTRAL_INFANT = [\"a baby's hand\"]\n",
        "t_fist_ctx = text_mean([t.format(\"fist\")             for t in TEMPLATES_INFANT] +\n",
        "                       [t.format(\"fingers curled\")   for t in TEMPLATES_INFANT] +\n",
        "                       [t.format(\"thumb tucked\")     for t in TEMPLATES_INFANT])\n",
        "t_open_ctx = text_mean([t.format(\"open\")             for t in TEMPLATES_INFANT] +\n",
        "                       [t.format(\"fingers extended\") for t in TEMPLATES_INFANT] +\n",
        "                       [t.format(\"palm visible\")     for t in TEMPLATES_INFANT])\n",
        "t_neutral  = text_mean(NEUTRAL_INFANT)\n",
        "\n",
        "dir_vec = (t_fist_ctx - t_neutral) - (t_open_ctx - t_neutral)\n",
        "dir_vec = dir_vec / dir_vec.norm()\n",
        "\n",
        "def directional_vote(img_feat, k=6.0):\n",
        "    s = float((img_feat @ dir_vec).item())\n",
        "    return 1.0 / (1.0 + math.exp(-k * s))\n",
        "\n",
        "def center_crop_scale(img: Image.Image, scale=0.92):\n",
        "    W, H = img.size\n",
        "    w = int(W*scale); h = int(H*scale)\n",
        "    x0 = (W - w)//2; y0 = (H - h)//2\n",
        "    return img.crop((x0, y0, x0+w, y0+h))\n",
        "\n",
        "def tta_images(pil_img):\n",
        "    imgs = []\n",
        "    base = pil_img\n",
        "    imgs.append(base)\n",
        "    imgs.append(ImageOps.mirror(base))\n",
        "    imgs.append(base.rotate(12,  resample=Image.BICUBIC, expand=False))\n",
        "    imgs.append(base.rotate(-12, resample=Image.BICUBIC, expand=False))\n",
        "    imgs.append(center_crop_scale(base, 0.95))\n",
        "    imgs.append(center_crop_scale(base, 0.90))\n",
        "    return imgs\n",
        "\n",
        "@torch.no_grad()\n",
        "def embed_image(pil_img):\n",
        "    x = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    f = model.encode_image(x)\n",
        "    f = f / f.norm(dim=-1, keepdim=True)\n",
        "    return f.squeeze(0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def bucket_scores_from_feat(img_feat, mode=\"max\", temp=1.12):\n",
        "    if mode in (\"max\", \"mean_prob\"):\n",
        "        logits_fist = (img_feat @ text_fist.T) * LOGIT_SCALE / temp\n",
        "        logits_open = (img_feat @ text_open.T) * LOGIT_SCALE / temp\n",
        "        logits_all  = torch.cat([logits_fist, logits_open], dim=0)\n",
        "        probs_all   = logits_all.softmax(dim=-1).detach().cpu().numpy()\n",
        "        pf = probs_all[:len(PROMPTS_FIST)]\n",
        "        po = probs_all[len(PROMPTS_FIST):]\n",
        "        if mode == \"max\":\n",
        "            return float(pf.max()), float(po.max())\n",
        "        else:\n",
        "            return float(pf.mean()), float(po.mean())\n",
        "    elif mode == \"mean_feat\":\n",
        "        logits2 = torch.stack([\n",
        "            (img_feat @ text_fist_mean) * LOGIT_SCALE / temp,\n",
        "            (img_feat @ text_open_mean) * LOGIT_SCALE / temp\n",
        "        ], dim=0)\n",
        "        probs2 = logits2.softmax(dim=-1).detach().cpu().numpy()\n",
        "        return float(probs2[0]), float(probs2[1])\n",
        "    else:\n",
        "        raise ValueError(\"DECISION_MODE csak: 'max', 'mean_prob', 'mean_feat' lehet.\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def decide_final_tta(pil_img):\n",
        "    aug_imgs = tta_images(pil_img)\n",
        "\n",
        "    pairs = []\n",
        "    dbg_top_f, dbg_top_o = None, None\n",
        "    for idx, aug in enumerate(aug_imgs):\n",
        "        f = embed_image(aug)\n",
        "        sf, so = bucket_scores_from_feat(f, mode=DECISION_MODE, temp=TEMP)\n",
        "        pairs.append((sf, so))\n",
        "        if idx == 0 and DECISION_MODE in (\"max\", \"mean_prob\"):\n",
        "            logits_fist = (f @ text_fist.T) * LOGIT_SCALE / TEMP\n",
        "            logits_open = (f @ text_open.T) * LOGIT_SCALE / TEMP\n",
        "            probs_all = torch.cat([logits_fist, logits_open], dim=0).softmax(dim=-1).detach().cpu().numpy()\n",
        "            pf = probs_all[:len(PROMPTS_FIST)]\n",
        "            po = probs_all[len(PROMPTS_FIST):]\n",
        "            fi = pf.argsort()[::-1][:TOPK_SHOW]\n",
        "            oi = po.argsort()[::-1][:TOPK_SHOW]\n",
        "            dbg_top_f = [(PROMPTS_FIST[i], float(pf[i])) for i in fi]\n",
        "            dbg_top_o = [(PROMPTS_OPEN[i], float(po[i])) for i in oi]\n",
        "\n",
        "    f_arr = np.array([p[0] for p in pairs]); o_arr = np.array([p[1] for p in pairs])\n",
        "    def agg(arr):\n",
        "        arr_sorted = np.sort(arr)\n",
        "        n = len(arr_sorted)\n",
        "        lo = int(np.floor(n * 0.20))\n",
        "        hi = int(np.ceil(n * 0.90))\n",
        "        if hi <= lo:\n",
        "            tm = float(arr.mean())\n",
        "        else:\n",
        "            tm = float(arr_sorted[lo:hi].mean())\n",
        "        return 0.7 * tm + 0.3 * float(arr.max())\n",
        "\n",
        "    score_fist = agg(f_arr)\n",
        "    score_open = agg(o_arr)\n",
        "\n",
        "    f0 = embed_image(pil_img)\n",
        "    p_dir_fist = directional_vote(f0, k=6.0)\n",
        "\n",
        "    denom = (score_fist + score_open) if (score_fist + score_open) > 1e-8 else 1.0\n",
        "    p_bucket_fist = score_fist / denom\n",
        "\n",
        "    p_fist = W_BUCKET * p_bucket_fist + W_DIR * p_dir_fist\n",
        "    p_fist_eff = min(max(p_fist + BIAS_DELTA, 0.0), 1.0)\n",
        "\n",
        "    pred = \"ÖKÖLBE SZORÍTVA\" if p_fist_eff >= 0.5 else \"NINCS ÖKÖLBE SZORÍTVA\"\n",
        "    conf = max(p_fist_eff, 1.0 - p_fist_eff)\n",
        "\n",
        "    margin = abs(score_fist - score_open)\n",
        "    uncertain = (conf < UNCERT_THRESH) and (margin < MARGIN_MIN)\n",
        "\n",
        "    if uncertain:\n",
        "        pred = f\"{pred} (BIZONYTALAN)\"\n",
        "\n",
        "    dbg = {\n",
        "        \"top_fist\": dbg_top_f or [(\"n/a\", score_fist)],\n",
        "        \"top_open\": dbg_top_o or [(\"n/a\", score_open)],\n",
        "        \"score_fist\": score_fist, \"score_open\": score_open,\n",
        "        \"p_bucket_fist\": float(p_bucket_fist),\n",
        "        \"p_dir_fist\": float(p_dir_fist),\n",
        "        \"p_fist_mix\": float(p_fist),\n",
        "        \"p_fist_eff\": float(p_fist_eff),\n",
        "        \"margin\": float(margin),\n",
        "        \"uncertain\": bool(uncertain),\n",
        "    }\n",
        "    return pred, conf, dbg\n",
        "\n",
        "print(\"Válassz ki egy vagy több képet (pl. .jpg, .png).\")\n",
        "uploaded = files.upload()\n",
        "os.makedirs(\"infant_hand_images\", exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "for fname, data in uploaded.items():\n",
        "    path = os.path.join(\"infant_hand_images\", fname)\n",
        "    with open(path, \"wb\") as f: f.write(data)\n",
        "\n",
        "    try:\n",
        "        img = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Hiba a {fname} megnyitásakor: {e}\")\n",
        "        continue\n",
        "\n",
        "    pred, conf, dbg = decide_final_tta(img)\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(img); plt.axis('off')\n",
        "    plt.title(\n",
        "        f\"{fname}\\n{pred} (bizt.: {conf:.2f}) | TEMP={TEMP}, mode={DECISION_MODE}, bias={BIAS_DELTA}\\n\"\n",
        "        f\"score_fist={dbg['score_fist']:.2f}, score_open={dbg['score_open']:.2f}, \"\n",
        "        f\"p_dir={dbg['p_dir_fist']:.2f}, p_mix={dbg['p_fist_mix']:.2f}, margin={dbg['margin']:.2f}\"\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    print(\"FIST – TOP sorok:\")\n",
        "    for s, p in dbg[\"top_fist\"]:\n",
        "        print(f\"  {p:5.3f}  |  {s}\")\n",
        "    print(\"OPEN – TOP sorok:\")\n",
        "    for s, p in dbg[\"top_open\"]:\n",
        "        print(f\"  {p:5.3f}  |  {s}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    rows.append({\n",
        "        \"fájl\": fname,\n",
        "        \"predikció\": pred,\n",
        "        \"biztonság\": conf,\n",
        "        \"score_fist\": dbg[\"score_fist\"],\n",
        "        \"score_open\": dbg[\"score_open\"],\n",
        "        \"p_bucket_fist\": dbg[\"p_bucket_fist\"],\n",
        "        \"p_dir_fist\": dbg[\"p_dir_fist\"],\n",
        "        \"p_fist_mix\": dbg[\"p_fist_mix\"],\n",
        "        \"p_fist_eff\": dbg[\"p_fist_eff\"],\n",
        "        \"margin\": dbg[\"margin\"],\n",
        "        \"bizonytalan\": dbg[\"uncertain\"],\n",
        "        \"modell\": MODEL_NAME\n",
        "    })\n",
        "\n",
        "if rows:\n",
        "    df = pd.DataFrame(rows).sort_values(by=\"biztonság\", ascending=False)\n",
        "    from IPython.display import display\n",
        "    display(df)\n",
        "    df.to_csv(\"clip_infant_hand_results.csv\", index=False)\n",
        "    print(\"Eredmények mentve: clip_infant_hand_results.csv\")\n",
        "else:\n",
        "    print(\"Nem sikerült kiértékelni a képeket.\")\n"
      ],
      "metadata": {
        "id": "ugv06SAeaXgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}